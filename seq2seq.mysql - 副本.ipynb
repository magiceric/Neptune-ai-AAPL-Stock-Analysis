{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a931760a68830a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:14:48.577767Z",
     "start_time": "2024-04-01T11:14:08.262856Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "# 随机数种子\n",
    "np.random.seed(0)\n",
    " \n",
    " \n",
    "class StandardScaler():\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    " \n",
    "    def fit(self, data):\n",
    "        self.mean = data.mean(0)\n",
    "        self.std = data.std(0)\n",
    " \n",
    "    def transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data - mean) / std\n",
    " \n",
    "    def inverse_transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        if data.shape[-1] != mean.shape[-1]:\n",
    "            mean = mean[-1:]\n",
    "            std = std[-1:]\n",
    "        return (data * std) + mean\n",
    " \n",
    "\n",
    " \n",
    "def plot_loss_data(data):\n",
    "    # 使用Matplotlib绘制线图\n",
    "    plt.figure()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data, marker='o')\n",
    " \n",
    "    # 添加标题\n",
    "    plt.title(\"loss results Plot\")\n",
    " \n",
    "    # 显示图例\n",
    "    plt.legend([\"Loss\"])\n",
    " \n",
    "    plt.show()\n",
    " \n",
    "\n",
    " \n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        sequence, label = self.sequences[index]\n",
    "        return torch.Tensor(sequence), torch.Tensor(label)\n",
    " \n",
    " \n",
    "\n",
    "def create_inout_sequences(input_data, tw, pre_len, config):\n",
    "    # 创建时间序列数据专用的数据分割器\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i:i + tw]\n",
    "        if (i + tw + pre_len) > len(input_data):\n",
    "            break\n",
    "        if config.feature == 'MS':\n",
    "            train_label = input_data[:, -1:][i + tw:i + tw + pre_len]\n",
    "        else:\n",
    "            train_label = input_data[i + tw:i + tw + pre_len]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    " \n",
    " \n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    # 平均绝对误差\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae\n",
    " \n",
    "\n",
    " \n",
    "def create_dataloader(config, device):\n",
    "    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>创建数据加载器<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    database_connection_string = 'mysql+pymysql://stock:Abcd1234!!@192.168.3.7:3306/aistock'\n",
    "    engine = sqlalchemy.create_engine(database_connection_string)\n",
    "    df = pd.read_sql_query(f\"SELECT trade_date, vol, high, low, open, close FROM historical_data_for_seq2seq WHERE ts_code = '{config.tsCode}'\", engine)  # 从MySQL数据库读取特定股票代码的数据\n",
    "    print(df)\n",
    "    pre_len = config.pre_len  # 预测未来数据的长度\n",
    "    train_window = config.window_size  # 观测窗口\n",
    "    # 将特征列移到末尾\n",
    "    target_data = df[[config.target]]\n",
    "    df = df.drop(config.target, axis=1)\n",
    "    df = pd.concat((df, target_data), axis=1)\n",
    " \n",
    "    cols_data = df.columns[1:]\n",
    "    df_data = df[cols_data]\n",
    " \n",
    "    # 这里加一些数据的预处理, 最后需要的格式是pd.series\n",
    "    true_data = df_data.values\n",
    " \n",
    "    # 定义标准化优化器\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(true_data)\n",
    " \n",
    "    train_data = true_data[int(0.3 * len(true_data)):]\n",
    "    valid_data = true_data[int(0.15 * len(true_data)):int(0.30 * len(true_data))]\n",
    "    test_data = true_data[:int(0.15 * len(true_data))]\n",
    "    print(\"训练集尺寸:\", len(train_data), \"测试集尺寸:\", len(test_data), \"验证集尺寸:\", len(valid_data))\n",
    " \n",
    "    # 进行标准化处理\n",
    "    train_data_normalized = scaler.transform(train_data)\n",
    "    test_data_normalized = scaler.transform(test_data)\n",
    "    valid_data_normalized = scaler.transform(valid_data)\n",
    " \n",
    "    # 转化为深度学习模型需要的类型Tensor\n",
    "    train_data_normalized = torch.FloatTensor(train_data_normalized).to(device)\n",
    "    test_data_normalized = torch.FloatTensor(test_data_normalized).to(device)\n",
    "    valid_data_normalized = torch.FloatTensor(valid_data_normalized).to(device)\n",
    " \n",
    "    # 定义训练器的的输入\n",
    "    train_inout_seq = create_inout_sequences(train_data_normalized, train_window, pre_len, config)\n",
    "    test_inout_seq = create_inout_sequences(test_data_normalized, train_window, pre_len, config)\n",
    "    valid_inout_seq = create_inout_sequences(valid_data_normalized, train_window, pre_len, config)\n",
    " \n",
    "    # 创建数据集\n",
    "    train_dataset = TimeSeriesDataset(train_inout_seq)\n",
    "    test_dataset = TimeSeriesDataset(test_inout_seq)\n",
    "    valid_dataset = TimeSeriesDataset(valid_inout_seq)\n",
    " \n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    " \n",
    "    print(\"通过滑动窗口共有训练集数据：\", len(train_inout_seq), \"转化为批次数据:\", len(train_loader))\n",
    "    print(\"通过滑动窗口共有测试集数据：\", len(test_inout_seq), \"转化为批次数据:\", len(test_loader))\n",
    "    print(\"通过滑动窗口共有验证集数据：\", len(valid_inout_seq), \"转化为批次数据:\", len(valid_loader))\n",
    "    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>创建数据加载器完成<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    return train_loader, test_loader, valid_loader, scaler\n",
    " \n",
    "\n",
    " \n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, rnn_num_layers=1, input_feature_len=1, sequence_len=168, hidden_size=100, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_feature_len = input_feature_len\n",
    "        self.num_layers = rnn_num_layers\n",
    "        self.rnn_directions = 2 if bidirectional else 1\n",
    "        self.lstm = nn.LSTM(\n",
    "            num_layers=rnn_num_layers,\n",
    "            input_size=input_feature_len,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    " \n",
    "    def forward(self, input_seq):\n",
    " \n",
    "        ht = torch.zeros(self.num_layers * self.rnn_directions, input_seq.size(0), self.hidden_size, device='cuda')\n",
    "        ct = ht.clone()\n",
    "        if input_seq.ndim < 3:\n",
    "            input_seq.unsqueeze_(2)\n",
    "        lstm_out, (ht, ct) = self.lstm(input_seq, (ht,ct))\n",
    "        if self.rnn_directions > 1:\n",
    "            lstm_out = lstm_out.view(input_seq.size(0), self.sequence_len, self.rnn_directions, self.hidden_size)\n",
    "            lstm_out = torch.sum(lstm_out, axis=2)\n",
    "        return lstm_out, ht.squeeze(0)\n",
    " \n",
    "\n",
    "class AttentionDecoderCell(nn.Module):\n",
    "    def __init__(self, input_feature_len, out_put, sequence_len, hidden_size):\n",
    "        super().__init__()\n",
    "        # attention - inputs - (decoder_inputs, prev_hidden)\n",
    "        self.attention_linear = nn.Linear(hidden_size + input_feature_len, sequence_len)\n",
    "        # attention_combine - inputs - (decoder_inputs, attention * encoder_outputs)\n",
    "        self.decoder_rnn_cell = nn.LSTMCell(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, input_feature_len)\n",
    " \n",
    "    def forward(self, encoder_output, prev_hidden, y):\n",
    "        if prev_hidden.ndimension() == 3:\n",
    "            prev_hidden = prev_hidden[-1]  # 保留最后一层的信息\n",
    "        attention_input = torch.cat((prev_hidden, y), axis=1)\n",
    "        attention_weights = F.softmax(self.attention_linear(attention_input), dim=-1).unsqueeze(1)\n",
    "        attention_combine = torch.bmm(attention_weights, encoder_output).squeeze(1)\n",
    "        rnn_hidden, rnn_hidden = self.decoder_rnn_cell(attention_combine, (prev_hidden, prev_hidden))\n",
    "        output = self.out(rnn_hidden)\n",
    "        return output, rnn_hidden\n",
    " \n",
    " \n",
    "\n",
    "class EncoderDecoderWrapper(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, pred_len, window_size, teacher_forcing=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = LSTMEncoder(num_layers, input_size, window_size, hidden_size)\n",
    "        self.decoder_cell = AttentionDecoderCell(input_size, output_size,  window_size, hidden_size)\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.pred_len = pred_len\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    " \n",
    " \n",
    "    def __call__(self, xb, yb=None):\n",
    "        input_seq = xb\n",
    "        encoder_output, encoder_hidden = self.encoder(input_seq)\n",
    "        prev_hidden = encoder_hidden\n",
    "        if torch.cuda.is_available():\n",
    "            outputs = torch.zeros(self.pred_len, input_seq.size(0), self.input_size, device='cuda')\n",
    "        else:\n",
    "            outputs = torch.zeros(input_seq.size(0), self.output_size)\n",
    "        y_prev = input_seq[:, -1, :]\n",
    "        for i in range(self.pred_len):\n",
    "            if (yb is not None) and (i > 0) and (torch.rand(1) < self.teacher_forcing):\n",
    "                y_prev = yb[:, i].unsqueeze(1)\n",
    "            rnn_output, prev_hidden = self.decoder_cell(encoder_output, prev_hidden, y_prev)\n",
    "            y_prev = rnn_output\n",
    "            outputs[i, :, :] = rnn_output\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "        if self.output_size == 1:\n",
    "            outputs = self.linear(outputs)\n",
    "        return outputs\n",
    " \n",
    " \n",
    " \n",
    "\n",
    "def train(model, args, scaler, device):\n",
    "    start_time = time.time()  # 计算起始时间\n",
    "    model = model\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    epochs = args.epochs\n",
    "    model.train()  # 训练模式\n",
    "    results_loss = []\n",
    "    for i in tqdm(range(epochs)):\n",
    "        losss = []\n",
    "        for seq, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            y_pred = model(seq)\n",
    " \n",
    "            single_loss = loss_function(y_pred, labels)\n",
    " \n",
    "            single_loss.backward()\n",
    " \n",
    "            optimizer.step()\n",
    "            losss.append(single_loss.detach().cpu().numpy())\n",
    "        tqdm.write(f\"\\t Epoch {i + 1} / {epochs}, Loss: {sum(losss) / len(losss)}\")\n",
    "        results_loss.append(sum(losss) / len(losss))\n",
    " \n",
    "        # Generate the model save path with timestamp and tsCode\n",
    "        save_path = f\"trainedModels/save_model_{args.tsCode}_{time.strftime('%Y%m%d')}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        time.sleep(0.1)\n",
    " \n",
    "    # valid_loss = valid(model, args, scaler, valid_loader)\n",
    "    # 尚未引入学习率计划后期补上\n",
    "    # 保存模型\n",
    " \n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>模型已保存至{save_path}, 用时:{(time.time() - start_time) / 60:.4f} min<<<<<<<<<<<<<<<<<<\")\n",
    "    plot_loss_data(results_loss)\n",
    " \n",
    "\n",
    "def valid(model, args, scaler, valid_loader):\n",
    "    lstm_model = model\n",
    "    # 加载模型进行预测\n",
    "    model_path = f\"trainedModels/save_model_{args.tsCode}_{time.strftime('%Y%m%d')}.pth\"\n",
    "    lstm_model.load_state_dict(torch.load(model_path))\n",
    "    lstm_model.eval()  # 评估模式\n",
    "    losss = []\n",
    " \n",
    "    for seq, labels in valid_loader:\n",
    "        pred = lstm_model(seq)\n",
    "        mae = calculate_mae(pred.detach().numpy().cpu(), np.array(labels.detach().cpu()))  # MAE误差计算绝对值(预测值  - 真实值)\n",
    "        losss.append(mae)\n",
    " \n",
    "    print(\"验证集误差MAE:\", losss)\n",
    "    return sum(losss) / len(losss)\n",
    " \n",
    "\n",
    "def test(model, args, test_loader, scaler):\n",
    "    # 加载模型进行预测\n",
    "    losss = []\n",
    "    model = model\n",
    "    model_path = f\"trainedModels/save_model_{args.tsCode}_{time.strftime('%Y%m%d')}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # 评估模式\n",
    "    results = []\n",
    "    labels = []\n",
    "    for seq, label in test_loader:\n",
    "        pred = model(seq)\n",
    "        mae = calculate_mae(pred.detach().cpu().numpy(),\n",
    "                            np.array(label.detach().cpu()))  # MAE误差计算绝对值(预测值  - 真实值)\n",
    "        losss.append(mae)\n",
    "        pred = pred[:, 0, :]\n",
    "        label = label[:, 0, :]\n",
    "        pred = scaler.inverse_transform(pred.detach().cpu().numpy())\n",
    "        label = scaler.inverse_transform(label.detach().cpu().numpy())\n",
    "        for i in range(len(pred)):\n",
    "            results.append(pred[i][-1])\n",
    "            labels.append(label[i][-1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    print(\"测试集误差MAE:\", losss)\n",
    "    # 绘制历史数据\n",
    "    plt.plot(labels, label='TrueValue')\n",
    " \n",
    "    # 绘制预测数据\n",
    "    # 注意这里预测数据的起始x坐标是历史数据的最后一个点的x坐标\n",
    "    plt.plot(results, label='Prediction')\n",
    " \n",
    "    # 添加标题和图例\n",
    "    plt.title(\"test state\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    " \n",
    "\n",
    "# 检验模型拟合情况\n",
    "def inspect_model_fit(model, args, train_loader, scaler):\n",
    "    model = model\n",
    "    # model.load_state_dict(torch.load('save_model.pth'))\n",
    "    model_path = f\"trainedModels/save_model_{args.tsCode}_{time.strftime('%Y%m%d')}.pth\"\n",
    "    model.eval()  # 评估模式\n",
    "    results = []\n",
    "    labels = []\n",
    " \n",
    "    for seq, label in train_loader:\n",
    "        pred = model(seq)[:, 0, :]\n",
    "        label = label[:, 0, :]\n",
    "        pred = scaler.inverse_transform(pred.detach().cpu().numpy())\n",
    "        label = scaler.inverse_transform(label.detach().cpu().numpy())\n",
    "        for i in range(len(pred)):\n",
    "            results.append(pred[i][-1])\n",
    "            labels.append(label[i][-1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # 绘制历史数据\n",
    "    plt.plot(labels, label='History')\n",
    " \n",
    "    # 绘制预测数据\n",
    "    # 注意这里预测数据的起始x坐标是历史数据的最后一个点的x坐标\n",
    "    plt.plot(results, label='Prediction')\n",
    " \n",
    "    # 添加标题和图例\n",
    "    plt.title(\"inspect model fit state\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "\n",
    "def predict(model=None, args=None, device=None, scaler=None, rolling_data=None, show=False):\n",
    "    # 预测未知数据的功能\n",
    "    database_connection_string = 'mysql+pymysql://stock:Abcd1234!!@192.168.3.7:3306/aistock'\n",
    "    engine = sqlalchemy.create_engine(database_connection_string)\n",
    "    df = pd.read_sql_query(f\"SELECT trade_date, vol, high, low, open, close FROM historical_data_for_seq2seq WHERE ts_code = '{args.tsCode}'\", engine)  # 从MySQL数据库读取特定股票代码的数据\n",
    "    df = pd.concat((df, rolling_data), axis=0).reset_index(drop=True)\n",
    "    df = df.iloc[:, 1:][-args.window_size:].values  # 转换为nadarry\n",
    "    pre_data = scaler.transform(df)\n",
    "    tensor_pred = torch.FloatTensor(pre_data).to(device)\n",
    "    tensor_pred = tensor_pred.unsqueeze(0)  # 单次预测 , 滚动预测功能暂未开发后期补上\n",
    "    model = model\n",
    "    model_save_path = f\"trainedModels/save_model_{args.tsCode}_{time.strftime('%Y%m%d')}.pth\"\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.eval()  # 评估模式\n",
    " \n",
    "    pred = model(tensor_pred)[0]\n",
    " \n",
    "    pred = scaler.inverse_transform(pred.detach().cpu().numpy())\n",
    "    if show:\n",
    "        # 计算历史数据的长度\n",
    "        history_length = len(df[:, -1])\n",
    "        # 为历史数据生成x轴坐标\n",
    "        history_x = range(history_length)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        # 为预测数据生成x轴坐标\n",
    "        # 开始于历史数据的最后一个点的x坐标\n",
    "        prediction_x = range(history_length - 1, history_length + len(pred[:, -1]) - 1)\n",
    " \n",
    "        # 绘制历史数据\n",
    "        plt.plot(history_x, df[:, -1], label='History')\n",
    " \n",
    "        print(pred[:, -1])\n",
    "        # 绘制预测数据\n",
    "        # 注意这里预测数据的起始x坐标是历史数据的最后一个点的x坐标\n",
    "        plt.plot(prediction_x, pred[:, -1], marker='o', label='Prediction')\n",
    "        plt.axvline(history_length - 1, color='red')  # 在图像的x位置处画一条红色竖线\n",
    "        # 添加标题和图例\n",
    "        plt.title(\"History and Prediction\")\n",
    "        plt.legend()\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def rolling_predict(model=None, args=None, device=None, scaler=None):\n",
    "    # 滚动预测\n",
    "    database_connection_string = 'mysql+pymysql://stock:Abcd1234!!@192.168.3.7:3306/aistock'\n",
    "    engine = sqlalchemy.create_engine(database_connection_string)\n",
    "\n",
    "    # pre_data = pd.read_csv(args.roolling_data_path)\n",
    "    # pre_data = history_data\n",
    "    query = f\"\"\"\n",
    "    SELECT trade_date, vol, high, low, open, close \n",
    "    FROM historical_data_for_seq2seq \n",
    "    WHERE ts_code = '{args.tsCode}' \n",
    "    AND trade_date <= (\n",
    "        SELECT trade_date \n",
    "        FROM historical_data_for_seq2seq \n",
    "        WHERE ts_code = '{args.tsCode}' \n",
    "        ORDER BY trade_date DESC \n",
    "        LIMIT 1 OFFSET 0\n",
    "    ) \n",
    "    ORDER BY trade_date DESC \n",
    "    LIMIT 498\n",
    "    \"\"\"\n",
    "    pre_data = pd.read_sql_query(query, engine).iloc[::-1].reset_index(drop=True)  # 从MySQL数据库读取特定股票代码的数据，获取T-2交易日起前500个交易日的数据，并将数据顺序倒转\n",
    "    # 添加两条新数据\n",
    "    new_rows = [{'trade_date': '2024-04-02', 'vol': None, 'high': None, 'low': None, 'open': None, 'close': None},\n",
    "                {'trade_date': '2024-04-03', 'vol': None, 'high': None, 'low': None, 'open': None, 'close': None}]\n",
    "    pre_data = pd.concat([pre_data, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    print(pre_data)\n",
    "\n",
    "    pre_data_min_date = pre_data['trade_date'].astype(str).min()\n",
    "    query = f\"\"\"\n",
    "    SELECT {args.target} \n",
    "    FROM historical_data_for_seq2seq \n",
    "    WHERE ts_code = '{args.tsCode}' \n",
    "    AND trade_date < '{pre_data_min_date}' \n",
    "    ORDER BY trade_date DESC \n",
    "    LIMIT {args.window_size * 4}\n",
    "    \"\"\"\n",
    "    history_data = pd.read_sql_query(query, engine).iloc[::-1].reset_index(drop=True)\n",
    "    print(\"history_data : \", history_data)\n",
    "\n",
    "    columns = pre_data.columns[1:]\n",
    "    columns = ['forecast' + column for column in columns]\n",
    "    dict_of_lists = {column: [] for column in columns}\n",
    "    results = []\n",
    "    print(args)\n",
    "    for i in range(int(len(pre_data)/args.pre_len)):\n",
    "        rolling_data = pre_data.iloc[:args.pre_len * i]  # 转换为nadarry\n",
    "        pred = predict(model, args, device, scaler, rolling_data)\n",
    "        if args.feature == 'MS' or args.feature == 'S':\n",
    "            for i in range(args.pre_len):\n",
    "                # results.append(pred[i][0].detach().cpu().numpy())\n",
    "                results.append(pred[i][0])\n",
    "        else:\n",
    "            for j in range(args.output_size):\n",
    "                for i in range(args.pre_len):\n",
    "                    dict_of_lists[columns[j]].append(pred[i][j])\n",
    "        print(pred)\n",
    "    predDate = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    if args.feature == 'MS' or args.feature == 'S':\n",
    "        df = pd.DataFrame({'predDate': predDate, 'trade_date': pre_data['trade_date'], '{}'.format(args.target): pre_data[args.target],\n",
    "                           'forecast{}'.format(args.target): results})\n",
    "    else:\n",
    "        df = pd.DataFrame(dict_of_lists)\n",
    "        # print(\"df before concat : \", df)\n",
    "        df['predDate'] = predDate\n",
    "        df = pd.concat((pre_data, df), axis=1)\n",
    "        # print(\"df after concat : \", df)\n",
    "    \n",
    "    database_connection_string = 'mysql+pymysql://stock:Abcd1234!!@192.168.3.7:3306/aistock'\n",
    "    engine = sqlalchemy.create_engine(database_connection_string)\n",
    "    # Assuming 'engine' is the SQLAlchemy engine object already created for database connection\n",
    "    df.to_sql('interval_historical_data_for_seq2seq', con=engine, if_exists='append', index=False)\n",
    "    if args.feature == 'MS' or args.feature == 'S':\n",
    "        pre_len = len(results)\n",
    "    else:\n",
    "        pre_len = len(dict_of_lists['forecast' + args.target])\n",
    "    # 绘图\n",
    "    plt.figure()\n",
    "    if args.feature == 'MS' or args.feature == 'S':\n",
    "        plt.plot(range(len(history_data)), history_data,\n",
    "                 label='Past Actual Values')\n",
    "        # print(\"pre_data again : \", pre_data)\n",
    "        # print(\"pre_data[args.target] : \", pre_data[args.target])0\n",
    "        # print(\"pre_data[args.target][:pre_len].tolist() : \", pre_data[args.target][:pre_len].tolist())\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), pre_data[args.target][:pre_len].tolist(), label='Predicted Actual Values')\n",
    "        # print(\"results : \", results)\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), results, label='Predicted Future Values')\n",
    "    else:\n",
    "        plt.plot(range(len(history_data)), history_data,\n",
    "                 label='Past Actual Values')\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), pre_data[args.target][:pre_len].tolist(), label='Predicted Actual Values')\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), dict_of_lists['forecast' + args.target], label='Predicted Future Values')\n",
    "    # 添加图例\n",
    "    plt.legend()\n",
    "    plt.style.use('ggplot')\n",
    "    # 添加标题和轴标签\n",
    "    plt.title('Past vs Predicted Future Values')\n",
    "    plt.xlabel('Time Point')\n",
    "    plt.ylabel('Value')\n",
    "    # 在特定索引位置画一条直线\n",
    "    plt.axvline(x=len(history_data), color='blue', linestyle='--', linewidth=2)\n",
    "    # 显示图表\n",
    "    plt.savefig('forcast.png')\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "\n",
    " \n",
    "parser = argparse.ArgumentParser(description='Time Series forecast')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('-model', type=str, default='LSTM2LSTM', help=\"模型持续更新\")\n",
    "parser.add_argument('-window_size', type=int, default=64, help=\"时间窗口大小, window_size > pre_len\")\n",
    "parser.add_argument('-pre_len', type=int, default=2, help=\"预测未来数据长度\")\n",
    "\n",
    "\n",
    "# data\n",
    "parser.add_argument('-shuffle', action='store_true', default=True, help=\"是否打乱数据加载器中的数据顺序\")\n",
    "# parser.add_argument('-data_path', type=str, default='ETTh1.csv', help=\"你的数据数据地址\")\n",
    "parser.add_argument('-target', type=str, default='close', help='你需要预测的特征列，这个值会最后保存在csv文件里')\n",
    "parser.add_argument('-input_size', type=int, default=5, help='你的特征个数不算时间那一列')\n",
    "# parser.add_argument('-feature', type=str, default='M', help='[M, S, MS],多元预测多元,单元预测单元,多元预测单元')\n",
    "parser.add_argument('-feature', type=str, default='MS', help='[M, S, MS],多元预测多元,单元预测单元,多元预测单元')\n",
    "parser.add_argument('-tsCode', type=str, default='000001.SZ', help=\"指定股票代码\")\n",
    "\n",
    "\n",
    "# learning\n",
    "parser.add_argument('-lr', type=float, default=0.001, help=\"学习率\")\n",
    "parser.add_argument('-drop_out', type=float, default=0.05, help=\"随机丢弃概率,防止过拟合\")\n",
    "parser.add_argument('-epochs', type=int, default=50, help=\"训练轮次\")\n",
    "parser.add_argument('-batch_size', type=int, default=16, help=\"批次大小\")\n",
    "parser.add_argument('-save_path', type=str, default='models')\n",
    "\n",
    "\n",
    "# model\n",
    "parser.add_argument('-hidden_size', type=int, default=128, help=\"隐藏层单元数\")\n",
    "parser.add_argument('-laryer_num', type=int, default=2)\n",
    "\n",
    "\n",
    "# device\n",
    "parser.add_argument('-use_gpu', type=bool, default=True)\n",
    "parser.add_argument('-device', type=int, default=0, help=\"只设置最多支持单个gpu训练\")\n",
    "\n",
    "\n",
    "# option\n",
    "parser.add_argument('-train', type=bool, default=True)\n",
    "parser.add_argument('-test', type=bool, default=True)\n",
    "parser.add_argument('-predict', type=bool, default=True)\n",
    "parser.add_argument('-inspect_fit', type=bool, default=True)\n",
    "parser.add_argument('-lr-scheduler', type=bool, default=True)\n",
    "\n",
    "\n",
    "# 可选部分，滚动预测如果想要进行这个需要你有一个额外的文件和你的训练数据集完全相同但是数据时间点不同。\n",
    "parser.add_argument('-rolling_predict', type=bool, default=True)\n",
    "\n",
    "import sys\n",
    "\n",
    "# Modify the condition to check for any argument that starts with '--f=' and remove it\n",
    "sys.argv = [arg for arg in sys.argv if not arg.startswith('--f=')]\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "if isinstance(args.device, int) and args.use_gpu:\n",
    "    device = torch.device(\"cuda:\" + f'{args.device}')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"使用设备:\", device)\n",
    "train_loader, test_loader, valid_loader, scaler = create_dataloader(args, device)\n",
    "\n",
    "if args.feature == 'MS' or args.feature == 'S':\n",
    "    args.output_size = 1\n",
    "else:\n",
    "    args.output_size = args.input_size\n",
    "\n",
    "print(args)\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "try:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始初始化{args.model}模型<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    model = EncoderDecoderWrapper(args.input_size, args.output_size, args.hidden_size, args.laryer_num, args.pre_len, args.window_size).to(device)\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始初始化{args.model}模型成功<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "except:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始初始化{args.model}模型失败<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "if args.train:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始{args.model}模型训练<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    train(model, args, scaler, device)\n",
    "\n",
    "if args.test:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始{args.model}模型测试<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    test(model, args, test_loader, scaler)\n",
    "\n",
    "if args.inspect_fit:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始检验{args.model}模型拟合情况<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    inspect_model_fit(model, args, train_loader, scaler)\n",
    "\n",
    "if args.predict:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>预测未来{args.pre_len}条数据<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    predict(model, args, device, scaler,show=True)\n",
    "\n",
    "if args.predict:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>滚动预测未来{args.pre_len}条数据<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    rolling_predict(model, args, device, scaler)\n",
    "    end_time = time.time()\n",
    "    print(f\"滚动预测执行消耗时间: {end_time - start_time}秒\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
