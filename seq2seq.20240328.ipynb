{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    " \n",
    "# 随机数种子\n",
    "np.random.seed(0)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler():\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    " \n",
    "    def fit(self, data):\n",
    "        self.mean = data.mean(0)\n",
    "        self.std = data.std(0)\n",
    " \n",
    "    def transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data - mean) / std\n",
    " \n",
    "    def inverse_transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        if data.shape[-1] != mean.shape[-1]:\n",
    "            mean = mean[-1:]\n",
    "            std = std[-1:]\n",
    "        return (data * std) + mean\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_data(data):\n",
    "    # 使用Matplotlib绘制线图\n",
    "    plt.figure()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data, marker='o')\n",
    " \n",
    "    # 添加标题\n",
    "    plt.title(\"loss results Plot\")\n",
    " \n",
    "    # 显示图例\n",
    "    plt.legend([\"Loss\"])\n",
    " \n",
    "    plt.show()\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        sequence, label = self.sequences[index]\n",
    "        return torch.Tensor(sequence), torch.Tensor(label)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw, pre_len, config):\n",
    "    # 创建时间序列数据专用的数据分割器\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i:i + tw]\n",
    "        if (i + tw + pre_len) > len(input_data):\n",
    "            break\n",
    "        if config.feature == 'MS':\n",
    "            train_label = input_data[:, -1:][i + tw:i + tw + pre_len]\n",
    "        else:\n",
    "            train_label = input_data[i + tw:i + tw + pre_len]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae(y_true, y_pred):\n",
    "    # 平均绝对误差\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(config, device):\n",
    "    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>创建数据加载器<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    df = pd.read_csv(config.data_path)  # 填你自己的数据地址,自动选取你最后一列数据为特征列 # 添加你想要预测的特征列\n",
    "    pre_len = config.pre_len  # 预测未来数据的长度\n",
    "    train_window = config.window_size  # 观测窗口\n",
    " \n",
    "    # 将特征列移到末尾\n",
    "    target_data = df[[config.target]]\n",
    "    df = df.drop(config.target, axis=1)\n",
    "    df = pd.concat((df, target_data), axis=1)\n",
    " \n",
    "    cols_data = df.columns[1:]\n",
    "    df_data = df[cols_data]\n",
    " \n",
    "    # 这里加一些数据的预处理, 最后需要的格式是pd.series\n",
    "    true_data = df_data.values\n",
    " \n",
    "    # 定义标准化优化器\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(true_data)\n",
    " \n",
    "    train_data = true_data[int(0.3 * len(true_data)):]\n",
    "    valid_data = true_data[int(0.15 * len(true_data)):int(0.30 * len(true_data))]\n",
    "    test_data = true_data[:int(0.15 * len(true_data))]\n",
    "    print(\"训练集尺寸:\", len(train_data), \"测试集尺寸:\", len(test_data), \"验证集尺寸:\", len(valid_data))\n",
    " \n",
    "    # 进行标准化处理\n",
    "    train_data_normalized = scaler.transform(train_data)\n",
    "    test_data_normalized = scaler.transform(test_data)\n",
    "    valid_data_normalized = scaler.transform(valid_data)\n",
    " \n",
    "    # 转化为深度学习模型需要的类型Tensor\n",
    "    train_data_normalized = torch.FloatTensor(train_data_normalized).to(device)\n",
    "    test_data_normalized = torch.FloatTensor(test_data_normalized).to(device)\n",
    "    valid_data_normalized = torch.FloatTensor(valid_data_normalized).to(device)\n",
    " \n",
    "    # 定义训练器的的输入\n",
    "    train_inout_seq = create_inout_sequences(train_data_normalized, train_window, pre_len, config)\n",
    "    test_inout_seq = create_inout_sequences(test_data_normalized, train_window, pre_len, config)\n",
    "    valid_inout_seq = create_inout_sequences(valid_data_normalized, train_window, pre_len, config)\n",
    " \n",
    "    # 创建数据集\n",
    "    train_dataset = TimeSeriesDataset(train_inout_seq)\n",
    "    test_dataset = TimeSeriesDataset(test_inout_seq)\n",
    "    valid_dataset = TimeSeriesDataset(valid_inout_seq)\n",
    " \n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    " \n",
    "    print(\"通过滑动窗口共有训练集数据：\", len(train_inout_seq), \"转化为批次数据:\", len(train_loader))\n",
    "    print(\"通过滑动窗口共有测试集数据：\", len(test_inout_seq), \"转化为批次数据:\", len(test_loader))\n",
    "    print(\"通过滑动窗口共有验证集数据：\", len(valid_inout_seq), \"转化为批次数据:\", len(valid_loader))\n",
    "    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>创建数据加载器完成<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    return train_loader, test_loader, valid_loader, scaler\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, rnn_num_layers=1, input_feature_len=1, sequence_len=168, hidden_size=100, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_feature_len = input_feature_len\n",
    "        self.num_layers = rnn_num_layers\n",
    "        self.rnn_directions = 2 if bidirectional else 1\n",
    "        self.lstm = nn.LSTM(\n",
    "            num_layers=rnn_num_layers,\n",
    "            input_size=input_feature_len,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    " \n",
    "    def forward(self, input_seq):\n",
    " \n",
    "        ht = torch.zeros(self.num_layers * self.rnn_directions, input_seq.size(0), self.hidden_size, device='cuda')\n",
    "        ct = ht.clone()\n",
    "        if input_seq.ndim < 3:\n",
    "            input_seq.unsqueeze_(2)\n",
    "        lstm_out, (ht, ct) = self.lstm(input_seq, (ht,ct))\n",
    "        if self.rnn_directions > 1:\n",
    "            lstm_out = lstm_out.view(input_seq.size(0), self.sequence_len, self.rnn_directions, self.hidden_size)\n",
    "            lstm_out = torch.sum(lstm_out, axis=2)\n",
    "        return lstm_out, ht.squeeze(0)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderCell(nn.Module):\n",
    "    def __init__(self, input_feature_len, out_put, sequence_len, hidden_size):\n",
    "        super().__init__()\n",
    "        # attention - inputs - (decoder_inputs, prev_hidden)\n",
    "        self.attention_linear = nn.Linear(hidden_size + input_feature_len, sequence_len)\n",
    "        # attention_combine - inputs - (decoder_inputs, attention * encoder_outputs)\n",
    "        self.decoder_rnn_cell = nn.LSTMCell(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, input_feature_len)\n",
    " \n",
    "    def forward(self, encoder_output, prev_hidden, y):\n",
    "        if prev_hidden.ndimension() == 3:\n",
    "            prev_hidden = prev_hidden[-1]  # 保留最后一层的信息\n",
    "        attention_input = torch.cat((prev_hidden, y), axis=1)\n",
    "        attention_weights = F.softmax(self.attention_linear(attention_input), dim=-1).unsqueeze(1)\n",
    "        attention_combine = torch.bmm(attention_weights, encoder_output).squeeze(1)\n",
    "        rnn_hidden, rnn_hidden = self.decoder_rnn_cell(attention_combine, (prev_hidden, prev_hidden))\n",
    "        output = self.out(rnn_hidden)\n",
    "        return output, rnn_hidden\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderWrapper(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, pred_len, window_size, teacher_forcing=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = LSTMEncoder(num_layers, input_size, window_size, hidden_size)\n",
    "        self.decoder_cell = AttentionDecoderCell(input_size, output_size,  window_size, hidden_size)\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.pred_len = pred_len\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    " \n",
    " \n",
    "    def __call__(self, xb, yb=None):\n",
    "        input_seq = xb\n",
    "        encoder_output, encoder_hidden = self.encoder(input_seq)\n",
    "        prev_hidden = encoder_hidden\n",
    "        if torch.cuda.is_available():\n",
    "            outputs = torch.zeros(self.pred_len, input_seq.size(0), self.input_size, device='cuda')\n",
    "        else:\n",
    "            outputs = torch.zeros(input_seq.size(0), self.output_size)\n",
    "        y_prev = input_seq[:, -1, :]\n",
    "        for i in range(self.pred_len):\n",
    "            if (yb is not None) and (i > 0) and (torch.rand(1) < self.teacher_forcing):\n",
    "                y_prev = yb[:, i].unsqueeze(1)\n",
    "            rnn_output, prev_hidden = self.decoder_cell(encoder_output, prev_hidden, y_prev)\n",
    "            y_prev = rnn_output\n",
    "            outputs[i, :, :] = rnn_output\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "        if self.output_size == 1:\n",
    "            outputs = self.linear(outputs)\n",
    "        return outputs\n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, args, scaler, device):\n",
    "    start_time = time.time()  # 计算起始时间\n",
    "    model = model\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    epochs = args.epochs\n",
    "    model.train()  # 训练模式\n",
    "    results_loss = []\n",
    "    for i in tqdm(range(epochs)):\n",
    "        losss = []\n",
    "        for seq, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            y_pred = model(seq)\n",
    " \n",
    "            single_loss = loss_function(y_pred, labels)\n",
    " \n",
    "            single_loss.backward()\n",
    " \n",
    "            optimizer.step()\n",
    "            losss.append(single_loss.detach().cpu().numpy())\n",
    "        tqdm.write(f\"\\t Epoch {i + 1} / {epochs}, Loss: {sum(losss) / len(losss)}\")\n",
    "        results_loss.append(sum(losss) / len(losss))\n",
    " \n",
    " \n",
    "        torch.save(model.state_dict(), 'save_model.pth')\n",
    "        time.sleep(0.1)\n",
    " \n",
    "    # valid_loss = valid(model, args, scaler, valid_loader)\n",
    "    # 尚未引入学习率计划后期补上\n",
    "    # 保存模型\n",
    " \n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>模型已保存,用时:{(time.time() - start_time) / 60:.4f} min<<<<<<<<<<<<<<<<<<\")\n",
    "    plot_loss_data(results_loss)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, args, scaler, valid_loader):\n",
    "    lstm_model = model\n",
    "    # 加载模型进行预测\n",
    "    lstm_model.load_state_dict(torch.load('save_model.pth'))\n",
    "    lstm_model.eval()  # 评估模式\n",
    "    losss = []\n",
    " \n",
    "    for seq, labels in valid_loader:\n",
    "        pred = lstm_model(seq)\n",
    "        mae = calculate_mae(pred.detach().numpy().cpu(), np.array(labels.detach().cpu()))  # MAE误差计算绝对值(预测值  - 真实值)\n",
    "        losss.append(mae)\n",
    " \n",
    "    print(\"验证集误差MAE:\", losss)\n",
    "    return sum(losss) / len(losss)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, args, test_loader, scaler):\n",
    "    # 加载模型进行预测\n",
    "    losss = []\n",
    "    model = model\n",
    "    model.load_state_dict(torch.load('save_model.pth'))\n",
    "    model.eval()  # 评估模式\n",
    "    results = []\n",
    "    labels = []\n",
    "    for seq, label in test_loader:\n",
    "        pred = model(seq)\n",
    "        mae = calculate_mae(pred.detach().cpu().numpy(),\n",
    "                            np.array(label.detach().cpu()))  # MAE误差计算绝对值(预测值  - 真实值)\n",
    "        losss.append(mae)\n",
    "        pred = pred[:, 0, :]\n",
    "        label = label[:, 0, :]\n",
    "        pred = scaler.inverse_transform(pred.detach().cpu().numpy())\n",
    "        label = scaler.inverse_transform(label.detach().cpu().numpy())\n",
    "        for i in range(len(pred)):\n",
    "            results.append(pred[i][-1])\n",
    "            labels.append(label[i][-1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    print(\"测试集误差MAE:\", losss)\n",
    "    # 绘制历史数据\n",
    "    plt.plot(labels, label='TrueValue')\n",
    " \n",
    "    # 绘制预测数据\n",
    "    # 注意这里预测数据的起始x坐标是历史数据的最后一个点的x坐标\n",
    "    plt.plot(results, label='Prediction')\n",
    " \n",
    "    # 添加标题和图例\n",
    "    plt.title(\"test state\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检验模型拟合情况\n",
    "def inspect_model_fit(model, args, train_loader, scaler):\n",
    "    model = model\n",
    "    model.load_state_dict(torch.load('save_model.pth'))\n",
    "    model.eval()  # 评估模式\n",
    "    results = []\n",
    "    labels = []\n",
    " \n",
    "    for seq, label in train_loader:\n",
    "        pred = model(seq)[:, 0, :]\n",
    "        label = label[:, 0, :]\n",
    "        pred = scaler.inverse_transform(pred.detach().cpu().numpy())\n",
    "        label = scaler.inverse_transform(label.detach().cpu().numpy())\n",
    "        for i in range(len(pred)):\n",
    "            results.append(pred[i][-1])\n",
    "            labels.append(label[i][-1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # 绘制历史数据\n",
    "    plt.plot(labels, label='History')\n",
    " \n",
    "    # 绘制预测数据\n",
    "    # 注意这里预测数据的起始x坐标是历史数据的最后一个点的x坐标\n",
    "    plt.plot(results, label='Prediction')\n",
    " \n",
    "    # 添加标题和图例\n",
    "    plt.title(\"inspect model fit state\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model=None, args=None, device=None, scaler=None, rolling_data=None, show=False):\n",
    "    # 预测未知数据的功能\n",
    "    df = pd.read_csv(args.data_path)\n",
    "    df = pd.concat((df,rolling_data), axis=0).reset_index(drop=True)\n",
    "    df = df.iloc[:, 1:][-args.window_size:].values  # 转换为nadarry\n",
    "    pre_data = scaler.transform(df)\n",
    "    tensor_pred = torch.FloatTensor(pre_data).to(device)\n",
    "    tensor_pred = tensor_pred.unsqueeze(0)  # 单次预测 , 滚动预测功能暂未开发后期补上\n",
    "    model = model\n",
    "    model.load_state_dict(torch.load('save_model.pth'))\n",
    "    model.eval()  # 评估模式\n",
    " \n",
    "    pred = model(tensor_pred)[0]\n",
    " \n",
    "    pred = scaler.inverse_transform(pred.detach().cpu().numpy())\n",
    "    if show:\n",
    "        # 计算历史数据的长度\n",
    "        history_length = len(df[:, -1])\n",
    "        # 为历史数据生成x轴坐标\n",
    "        history_x = range(history_length)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        # 为预测数据生成x轴坐标\n",
    "        # 开始于历史数据的最后一个点的x坐标\n",
    "        prediction_x = range(history_length - 1, history_length + len(pred[:, -1]) - 1)\n",
    " \n",
    "        # 绘制历史数据\n",
    "        plt.plot(history_x, df[:, -1], label='History')\n",
    " \n",
    "        # 绘制预测数据\n",
    "        # 注意这里预测数据的起始x坐标是历史数据的最后一个点的x坐标\n",
    "        plt.plot(prediction_x, pred[:, -1], marker='o', label='Prediction')\n",
    "        plt.axvline(history_length - 1, color='red')  # 在图像的x位置处画一条红色竖线\n",
    "        # 添加标题和图例\n",
    "        plt.title(\"History and Prediction\")\n",
    "        plt.legend()\n",
    "    return pred\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predict(model=None, args=None, device=None, scaler=None):\n",
    "    # 滚动预测\n",
    "    history_data = pd.read_csv(args.data_path)[args.target][-args.window_size * 4:].reset_index(drop=True)\n",
    "    pre_data = pd.read_csv(args.roolling_data_path)\n",
    "    columns = pre_data.columns[1:]\n",
    "    columns = ['forecast' + column for column in columns]\n",
    "    dict_of_lists = {column: [] for column in columns}\n",
    "    results = []\n",
    "    for i in range(int(len(pre_data)/args.pre_len)):\n",
    "        rolling_data = pre_data.iloc[:args.pre_len * i]  # 转换为nadarry\n",
    "        pred = predict(model, args, device, scaler, rolling_data)\n",
    "        if args.feature == 'MS' or args.feature == 'S':\n",
    "            for i in range(args.pred_len):\n",
    "                results.append(pred[i][0].detach().cpu().numpy())\n",
    "        else:\n",
    "            for j in range(args.output_size):\n",
    "                for i in range(args.pre_len):\n",
    "                    dict_of_lists[columns[j]].append(pred[i][j])\n",
    "        print(pred)\n",
    "    if args.feature == 'MS' or args.feature == 'S':\n",
    "          df = pd.DataFrame({'date':pre_data['date'], '{}'.format(args.target): pre_data[args.target],\n",
    "                             'forecast{}'.format(args.target): pre_data[args.target]})\n",
    "          df.to_csv('Interval-{}'.format(args.data_path), index=False)\n",
    "    else:\n",
    "        df = pd.DataFrame(dict_of_lists)\n",
    "        new_df = pd.concat((pre_data,df), axis=1)\n",
    "        new_df.to_csv('Interval-{}'.format(args.data_path), index=False)\n",
    "    pre_len = len(dict_of_lists['forecast' + args.target])\n",
    "    # 绘图\n",
    "    plt.figure()\n",
    "    if args.feature == 'MS' or args.feature == 'S':\n",
    "        plt.plot(range(len(history_data)), history_data,\n",
    "                 label='Past Actual Values')\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), pre_data[args.target][:pre_len].tolist(), label='Predicted Actual Values')\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), results, label='Predicted Future Values')\n",
    "    else:\n",
    "        plt.plot(range(len(history_data)), history_data,\n",
    "                 label='Past Actual Values')\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), pre_data[args.target][:pre_len].tolist(), label='Predicted Actual Values')\n",
    "        plt.plot(range(len(history_data), len(history_data) + pre_len), dict_of_lists['forecast' + args.target], label='Predicted Future Values')\n",
    "    # 添加图例\n",
    "    plt.legend()\n",
    "    plt.style.use('ggplot')\n",
    "    # 添加标题和轴标签\n",
    "    plt.title('Past vs Predicted Future Values')\n",
    "    plt.xlabel('Time Point')\n",
    "    plt.ylabel('Value')\n",
    "    # 在特定索引位置画一条直线\n",
    "    plt.axvline(x=len(history_data), color='blue', linestyle='--', linewidth=2)\n",
    "    # 显示图表\n",
    "    plt.savefig('forcast.png')\n",
    "    plt.show()\n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-model MODEL] [-window_size WINDOW_SIZE]\n",
      "                             [-pre_len PRE_LEN] [-shuffle]\n",
      "                             [-data_path DATA_PATH] [-target TARGET]\n",
      "                             [-input_size INPUT_SIZE] [-feature FEATURE]\n",
      "                             [-lr LR] [-drop_out DROP_OUT] [-epochs EPOCHS]\n",
      "                             [-batch_size BATCH_SIZE] [-save_path SAVE_PATH]\n",
      "                             [-hidden_size HIDDEN_SIZE]\n",
      "                             [-laryer_num LARYER_NUM] [-use_gpu USE_GPU]\n",
      "                             [-device DEVICE] [-train TRAIN] [-test TEST]\n",
      "                             [-predict PREDICT] [-inspect_fit INSPECT_FIT]\n",
      "                             [-lr-scheduler LR_SCHEDULER]\n",
      "                             [-rolling_predict ROLLING_PREDICT]\n",
      "                             [-roolling_data_path ROOLLING_DATA_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\magic\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-98932UCdakK0OVpJU.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Time Series forecast')\n",
    "parser.add_argument('-model', type=str, default='LSTM2LSTM', help=\"模型持续更新\")\n",
    "parser.add_argument('-window_size', type=int, default=64, help=\"时间窗口大小, window_size > pre_len\")\n",
    "parser.add_argument('-pre_len', type=int, default=24, help=\"预测未来数据长度\")\n",
    "# data\n",
    "parser.add_argument('-shuffle', action='store_true', default=True, help=\"是否打乱数据加载器中的数据顺序\")\n",
    "parser.add_argument('-data_path', type=str, default='ETTh1.csv', help=\"你的数据数据地址\")\n",
    "parser.add_argument('-target', type=str, default='OT', help='你需要预测的特征列，这个值会最后保存在csv文件里')\n",
    "parser.add_argument('-input_size', type=int, default=7, help='你的特征个数不算时间那一列')\n",
    "parser.add_argument('-feature', type=str, default='M', help='[M, S, MS],多元预测多元,单元预测单元,多元预测单元')\n",
    "\n",
    "# learning\n",
    "parser.add_argument('-lr', type=float, default=0.001, help=\"学习率\")\n",
    "parser.add_argument('-drop_out', type=float, default=0.05, help=\"随机丢弃概率,防止过拟合\")\n",
    "parser.add_argument('-epochs', type=int, default=20, help=\"训练轮次\")\n",
    "parser.add_argument('-batch_size', type=int, default=16, help=\"批次大小\")\n",
    "parser.add_argument('-save_path', type=str, default='models')\n",
    "\n",
    "# model\n",
    "parser.add_argument('-hidden_size', type=int, default=128, help=\"隐藏层单元数\")\n",
    "parser.add_argument('-laryer_num', type=int, default=2)\n",
    "\n",
    "# device\n",
    "parser.add_argument('-use_gpu', type=bool, default=True)\n",
    "parser.add_argument('-device', type=int, default=0, help=\"只设置最多支持单个gpu训练\")\n",
    "\n",
    "# option\n",
    "parser.add_argument('-train', type=bool, default=True)\n",
    "parser.add_argument('-test', type=bool, default=True)\n",
    "parser.add_argument('-predict', type=bool, default=True)\n",
    "parser.add_argument('-inspect_fit', type=bool, default=True)\n",
    "parser.add_argument('-lr-scheduler', type=bool, default=True)\n",
    "# 可选部分，滚动预测如果想要进行这个需要你有一个额外的文件和你的训练数据集完全相同但是数据时间点不同。\n",
    "parser.add_argument('-rolling_predict', type=bool, default=True)\n",
    "parser.add_argument('-roolling_data_path', type=str, default='ETTh1Test.csv', help=\"你滚动数据集的地址，此部分属于进阶功能\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if isinstance(args.device, int) and args.use_gpu:\n",
    "    device = torch.device(\"cuda:\" + f'{args.device}')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"使用设备:\", device)\n",
    "train_loader, test_loader, valid_loader, scaler = create_dataloader(args, device)\n",
    "\n",
    "if args.feature == 'MS' or args.feature == 'S':\n",
    "    args.output_size = 1\n",
    "else:\n",
    "    args.output_size = args.input_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "try:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始初始化{args.model}模型<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    model = EncoderDecoderWrapper(args.input_size, args.output_size, args.hidden_size, args.laryer_num, args.pre_len, args.window_size).to(device)\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始初始化{args.model}模型成功<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "except:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始初始化{args.model}模型失败<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "if args.train:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始{args.model}模型训练<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    train(model, args, scaler, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.test:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始{args.model}模型测试<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    test(model, args, test_loader, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.inspect_fit:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>开始检验{args.model}模型拟合情况<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    inspect_model_fit(model, args, train_loader, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.predict:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>预测未来{args.pre_len}条数据<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    predict(model, args, device, scaler,show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.predict:\n",
    "    print(f\">>>>>>>>>>>>>>>>>>>>>>>>>滚动预测未来{args.pre_len}条数据<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    rolling_predict(model, args, device, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
