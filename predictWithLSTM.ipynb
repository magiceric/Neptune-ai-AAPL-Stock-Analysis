{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a29e23fe-99e1-4f5d-8300-d774440e5b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:12.084Z",
     "start_time": "2024-03-23T16:07:12.079566Z"
    }
   },
   "outputs": [],
   "source": [
    "from config import api_key, neptune_key\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Dropout, Activation\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical as np_utils\n",
    "\n",
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"magiceric/aaa\",\n",
    "    api_token=neptune_key,\n",
    "    capture_stdout=True,\n",
    "    capture_stderr=True,\n",
    "    capture_traceback=True,\n",
    "    capture_hardware_metrics=True\n",
    ")  # your credentials\n",
    "\n",
    "params = {\"learning_rate\": 0.001, \"optimizer\": \"Adam\"}\n",
    "run[\"parameters\"] = params\n",
    "\n",
    "for epoch in range(10):\n",
    "    run[\"train/loss\"].log(0.9 ** epoch)\n",
    "\n",
    "run[\"eval/f1_score\"] = 0.66\n",
    "\n",
    "run.stop()\n",
    "import tushare as ts\n",
    "\n",
    "ts.set_token('94cd405b2c1adff88930d17a3a3d6e5c0c53f4dc4945aeb264b2be3a')  # Set your tushare token\n",
    "pro = ts.pro_api()\n",
    "\n",
    "df = pro.daily(ts_code='600630.SH', start_date='19900101', end_date='20241231')\n",
    "\n",
    "# Adjusting the DataFrame to match the target data structure with modified keys\n",
    "last_refreshed_date = df.iloc[0]['trade_date'] if not df.empty else 'N/A'  # Assuming the first row is the latest\n",
    "data = {\n",
    "    \"Meta Data\": {\n",
    "        \"1. Information\": \"Daily Prices (open, high, low, close) and Volumes\",\n",
    "        \"2. Symbol\": \"600630.SH\",\n",
    "        \"3. Last Refreshed\": last_refreshed_date,\n",
    "        \"4. Output Size\": \"Full size\",\n",
    "        \"5. Time Zone\": \"Asia/Shanghai\"\n",
    "    },\n",
    "    \"Time Series (Daily)\": {date: {\"1. open\": str(row['open']), \"2. high\": str(row['high']), \"3. low\": str(row['low']), \"4. close\": str(row['close']), \"5. volume\": str(row['vol'])} for date, row in df.set_index('trade_date').iterrows()}\n",
    "}\n",
    "\n",
    "print(data)\n",
    "sz000001_df_json = pd.DataFrame.from_dict(data, orient='index')\n",
    "sz000001_df_json\n",
    "df_tushare = pro.daily(ts_code='600630.SH', start_date='19900101', end_date='20241231')\n",
    "sz000001_csv_df = pd.DataFrame({\n",
    "    \"timestamp\": df_tushare[\"trade_date\"],\n",
    "    \"open\": df_tushare[\"open\"],\n",
    "    \"high\": df_tushare[\"high\"],\n",
    "    \"low\": df_tushare[\"low\"],\n",
    "    \"close\": df_tushare[\"close\"],\n",
    "    \"volume\": df_tushare[\"vol\"]\n",
    "})\n",
    "print(sz000001_csv_df)\n",
    "\n",
    "len(sz000001_csv_df.close)\n",
    "df_copy = sz000001_csv_df.copy()\n",
    "date_close_df = df_copy.filter(['timestamp','close'], axis=1).iloc[::-1]\n",
    "date_close_df\n",
    "date_close_df.tail(5)\n",
    "stockprices = date_close_df\n",
    "#### Train-Test split for time-series ####\n",
    "test_ratio = 0.2\n",
    "training_ratio = 1 - test_ratio\n",
    "\n",
    "train_size = int(training_ratio * len(stockprices))\n",
    "test_size = int(test_ratio * len(stockprices))\n",
    "print(\"train_size: \" + str(train_size))\n",
    "print(\"test_size: \" + str(test_size))\n",
    "\n",
    "train = stockprices[:train_size][['timestamp', 'close']]\n",
    "test = stockprices[train_size:][['timestamp', 'close']]\n",
    "## Split the time-series data into training seq X and output value Y\n",
    "def extract_seqX_outcomeY(data, N, offset):\n",
    "    \"\"\"\n",
    "    Split time-series into training sequence X and outcome value Y\n",
    "    Args:\n",
    "        data - dataset \n",
    "        N - window size, e.g., 50 for 50 days of historical stock prices\n",
    "        offset - position to start the split\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(offset, len(data)):\n",
    "        X.append(data[i-N:i])\n",
    "        y.append(data[i])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "#### Calculate the metrics RMSE and MAPE ####\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE)  \n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(np.mean((y_true-y_pred)**2))                   \n",
    "    return rmse\n",
    "\n",
    "def calculate_mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Percentage Error (MAPE) %\n",
    "    \"\"\"\n",
    "    y_pred, y_true = np.array(y_pred), np.array(y_true)    \n",
    "    mape = np.mean(np.abs((y_true-y_pred) / y_true))*100    \n",
    "    return mape\n",
    "def calculate_perf_metrics(var, logNeptune=True, logmodelName='Simple MA'):\n",
    "    ### RMSE \n",
    "    rmse = calculate_rmse(np.array(stockprices[train_size:]['close']), np.array(stockprices[train_size:][var]))\n",
    "    ### MAPE \n",
    "    mape = calculate_mape(np.array(stockprices[train_size:]['close']), np.array(stockprices[train_size:][var]))\n",
    "    \n",
    "    ## Log images to Neptune new version \n",
    "    if logNeptune:        \n",
    "        npt_exp['RMSE'].log(rmse)\n",
    "        npt_exp['MAPE (%)'].log(mape)\n",
    "    \n",
    "    return rmse, mape\n",
    "def plot_stock_trend(var, cur_title, stockprices=stockprices, logNeptune=True, logmodelName='Simple MA'):\n",
    "    ax = stockprices[['close', var,'200day']].plot(figsize=(20, 10))\n",
    "    plt.grid(False)\n",
    "    plt.title(cur_title)\n",
    "    plt.axis('tight')\n",
    "    plt.ylabel('Stock Price ($)')\n",
    "\n",
    "    ## Log images to Neptune new version \n",
    "    if logNeptune:\n",
    "        npt_exp[f'Plot of Stock Predictions with {logmodelName}'].upload(neptune.types.File.as_image(ax.get_figure()))\n",
    "window_size = 50\n",
    "\n",
    "import neptune\n",
    "\n",
    "window_var = str(window_size) + 'day'\n",
    "\n",
    "layer_units, optimizer = 50, 'adam' \n",
    "cur_epochs = 15\n",
    "cur_batch_size = 20\n",
    "    \n",
    "cur_LSTM_pars = {'units': layer_units, \n",
    "                 'optimizer': optimizer, \n",
    "                 'batch_size': cur_batch_size, \n",
    "                 'epochs': cur_epochs\n",
    "                 }\n",
    "    \n",
    "# Create an experiment and log the model in Neptune new version\n",
    "npt_exp = neptune.init_project(    \n",
    "        api_token=neptune_key,\n",
    "        project=\"magiceric/aaa\", \n",
    "        # name='LSTM',         \n",
    "        # description='stock-prediction-machine-learning', \n",
    "        # tags=['stockprediction', 'LSTM','neptune']\n",
    "        )   \n",
    "npt_exp['LSTMPars'] = cur_LSTM_pars\n",
    "# scale our dataset\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(stockprices[['close']])\n",
    "scaled_data_train = scaled_data[:train.shape[0]]\n",
    "    \n",
    "# We use past 50 days’ stock prices for our training to predict the 51th day's closing price.\n",
    "X_train, y_train = extract_seqX_outcomeY(scaled_data_train, window_size, window_size)\n",
    "### Build a LSTM model and log model summary to Neptune ###    \n",
    "def Run_LSTM(X_train, layer_units=50, logNeptune=True, NeptuneProject=None):     \n",
    "    inp = Input(shape=(X_train.shape[1], 1))\n",
    "    \n",
    "    x = LSTM(units=layer_units, return_sequences=True)(inp)\n",
    "    x = LSTM(units=layer_units)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "    model = tf.keras.Model(inp, out)  # Corrected keras.Model to tf.keras.Model\n",
    "    \n",
    "    # Compile the LSTM neural net\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    ## !!! log to Neptune, e.g., set NeptuneProject = npt_exp (new version)\n",
    "    if logNeptune:\n",
    "        # Capture the model summary and log it to Neptune\n",
    "        from io import StringIO\n",
    "        model_summary = StringIO()\n",
    "        # model.summary(print_fn=lambda x: model_summary.write(x + '\\n'))\n",
    "        model.summary(print_fn=lambda x, **kwargs: model_summary.write(x + '\\n'))\n",
    "        model_summary.seek(0)\n",
    "        NeptuneProject['model_summary'].log(model_summary.read())\n",
    "        \n",
    "    return model   \n",
    "\n",
    "model = Run_LSTM(X_train, layer_units=layer_units, logNeptune=True, NeptuneProject=npt_exp)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=cur_epochs, batch_size=cur_batch_size, \n",
    "                    verbose=1, validation_split=0.1, shuffle=True)\n",
    "# predict stock prices using past window_size stock prices\n",
    "def preprocess_testdat(data=stockprices, scaler=scaler, window_size=window_size, test=test):    \n",
    "    raw = data[['close']].iloc[len(data) - len(test) - window_size:].values\n",
    "    # To avoid the warning, ensure the data passed to scaler.transform() has the same structure as the data used in scaler.fit()\n",
    "    # Specifically, ensure it's a DataFrame with column names matching those used in fitting.\n",
    "    raw_df = pd.DataFrame(raw, columns=['close'])\n",
    "    raw_scaled = scaler.transform(raw_df)\n",
    "    \n",
    "    X_test = []\n",
    "    for i in range(window_size, raw_scaled.shape[0]):\n",
    "        X_test.append(raw_scaled[i-window_size:i, 0])\n",
    "        \n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    return X_test\n",
    "\n",
    "X_test = preprocess_testdat()\n",
    "\n",
    "predicted_price_ = model.predict(X_test)\n",
    "predicted_price = scaler.inverse_transform(predicted_price_)\n",
    "\n",
    "# Plot predicted price vs actual closing price \n",
    "test['Predictions_lstm'] = predicted_price\n",
    "\n",
    "# 打印最后1天的日期和最后2天的实际值和预测值\n",
    "last_day = test.iloc[-1]['timestamp']\n",
    "last_day_actual_close = test.iloc[-1]['close']\n",
    "last_day_predicted_close = test.iloc[-1]['Predictions_lstm']\n",
    "second_last_day_actual_close = test.iloc[-2]['close']\n",
    "second_last_day_predicted_close = test.iloc[-2]['Predictions_lstm']\n",
    "\n",
    "print(f\"最后1天的日期: {last_day}\")\n",
    "print(f\"最后1天的实际收盘价: {last_day_actual_close}, 预测收盘价: {last_day_predicted_close}\")\n",
    "print(f\"倒数第二天的实际收盘价: {second_last_day_actual_close}, 预测收盘价: {second_last_day_predicted_close}\")\n",
    "\n",
    "# 预测后面两个交易日的收盘价\n",
    "# Instead of calculating future dates, use \"T+1\" and \"T+2\"\n",
    "future_dates = [\"T+1\", \"T+2\"]\n",
    "future_raw = np.array([predicted_price[-1]]).reshape(-1,1)  # Assuming the last predicted price for future prediction\n",
    "# Use a DataFrame for future_raw to match the structure expected by scaler\n",
    "future_raw_df = pd.DataFrame(future_raw, columns=['close'])\n",
    "future_raw_scaled = scaler.transform(future_raw_df)\n",
    "\n",
    "# Corrected future prediction preprocessing to match the expected input shape for the model\n",
    "future_X_test = np.repeat(future_raw_scaled.T, window_size, axis=0).reshape(1, window_size, 1)\n",
    "future_predicted_price_ = model.predict(future_X_test)\n",
    "future_predicted_price = scaler.inverse_transform(future_predicted_price_)\n",
    "\n",
    "# 预测“T+1”的收盘价\n",
    "print(f\"{future_dates[0]}预测收盘价: {future_predicted_price[0][0]}\")\n",
    "\n",
    "# 使用“T+1”的预测值来预测“T+2”\n",
    "future_raw_next_day = np.array([future_predicted_price[-1]]).reshape(-1,1)\n",
    "# Again, use a DataFrame for future_raw_next_day\n",
    "future_raw_next_day_df = pd.DataFrame(future_raw_next_day, columns=['close'])\n",
    "future_raw_next_day_scaled = scaler.transform(future_raw_next_day_df)\n",
    "future_X_test_next_day = np.repeat(future_raw_next_day_scaled.T, window_size, axis=0).reshape(1, window_size, 1)\n",
    "future_predicted_price_next_day_ = model.predict(future_X_test_next_day)\n",
    "future_predicted_price_next_day = scaler.inverse_transform(future_predicted_price_next_day_)\n",
    "\n",
    "# 预测“T+2”的收盘价\n",
    "print(f\"{future_dates[1]}预测收盘价: {future_predicted_price_next_day[0][0]}\")\n",
    "\n",
    "# Evaluate performance\n",
    "rmse_lstm = calculate_rmse(np.array(test['close']), np.array(test['Predictions_lstm']))\n",
    "mape_lstm = calculate_mape(np.array(test['close']), np.array(test['Predictions_lstm']))\n",
    "\n",
    "### Neptune new version\n",
    "npt_exp['RMSE'].log(rmse_lstm)\n",
    "npt_exp['MAPE (%)'].log(mape_lstm)\n",
    "\n",
    "### Plot prediction and true trends and log to Neptune         \n",
    "def plot_stock_trend_lstm(train, test, logNeptune=True):        \n",
    "    fig = plt.figure(figsize = (20,10))\n",
    "    plt.plot(train['timestamp'], train['close'], label = 'Train Closing Price')\n",
    "    plt.plot(test['timestamp'], test['close'], label = 'Test Closing Price')\n",
    "    plt.plot(test['timestamp'], test['Predictions_lstm'], label = 'Predicted Closing Price')\n",
    "    plt.title('LSTM Model')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stock Price ($)')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    \n",
    "## Log image to Neptune new version\n",
    "    if logNeptune:\n",
    "        npt_exp['Plot of Stock Predictions with LSTM'].upload(neptune.types.File.as_image(fig))  \n",
    "        \n",
    "plot_stock_trend_lstm(train, test)\n",
    "\n",
    "### Stop the run after logging for new version \n",
    "npt_exp.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
